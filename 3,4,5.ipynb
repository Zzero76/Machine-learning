{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdC80pEjTUZrX32vZ4U52h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zzero76/Machine-learning/blob/main/3%2C4%2C5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
        "from scipy.stats import randint as sp_randint"
      ],
      "metadata": {
        "id": "yKAJz3g7MImB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9L0YAbb5MB6t"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Zzero76/Machine-learning/main/123.csv\")\n",
        "df = df.drop(columns=['E','F'])\n",
        "X = df.drop(columns=['AH'])\n",
        "y = df['AH']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# fill missing values with the mean of the column\n",
        "df = df.fillna(df.mean())\n",
        "\n",
        "# check for duplicate rows\n",
        "print(df.duplicated().sum())\n",
        "\n",
        "# remove duplicate rows\n",
        "df = df.drop_duplicates()\n",
        "\n",
        "# check for inconsistent data types\n",
        "print(df.dtypes)\n",
        "\n",
        "# check for outliers\n",
        "print(df.describe())"
      ],
      "metadata": {
        "id": "3K99Kt-2OT5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# normalized the data set\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "print(X_scaled)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)"
      ],
      "metadata": {
        "id": "0UlGozZIQQLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_features = PolynomialFeatures(degree=2, include_bias=False)\n",
        "\n",
        "X_poly = poly_features.fit_transform(X_scaled_df)\n",
        "\n",
        "poly_reg_model = LinearRegression()\n",
        "poly_reg_model.fit(X_poly, y)\n",
        "\n",
        "intercept = poly_reg_model.intercept_\n",
        "coefficients = poly_reg_model.coef_\n",
        "\n",
        "print(\"Intercept:\", intercept)\n",
        "print(\"Coefficients:\", coefficients)\n",
        "\n",
        "feature_names = poly_features.get_feature_names_out(input_features=X_scaled_df.columns)\n",
        "print(\"\\nThe polynomial linear regression model is:\")\n",
        "print(f\"y = {intercept:.5f}\")\n",
        "for i, coef in enumerate(coefficients):\n",
        "  print(f\" + ({coef:.5f})*{feature_names[i]}\")"
      ],
      "metadata": {
        "id": "Xv78uGzYV4Ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "model = RandomForestRegressor()\n",
        "param_grid = {'n_estimators': [50, 100, 200],'max_features': ['auto', 'sqrt', 'log2'],'max_depth': [None, 10, 20, 30],'min_samples_split': [2, 5, 10]}\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters from grid search:\", grid_search.best_params_)\n",
        "best_model_grid = grid_search.best_estimator_\n",
        "\n",
        "from scipy.stats import randint as sp_randint\n",
        "\n",
        "param_dist = {'n_estimators': sp_randint(10, 200),'max_features': ['auto', 'sqrt', 'log2'],'max_depth': [None, 10, 20, 30, 50],'min_samples_split': sp_randint(2, 11)}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=model, param_distributions=param_dist, n_iter=100, cv=5, n_jobs=-1, verbose=2, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print(\"Best parameters from randomized search:\", random_search.best_params_)\n",
        "best_model_random = random_search.best_estimator_"
      ],
      "metadata": {
        "id": "FGsjgIphXAOd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e0b2387-c11a-4d6d-c388-366759d28a32"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters from grid search: {'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters from randomized search: {'max_depth': 30, 'max_features': 'auto', 'min_samples_split': 2, 'n_estimators': 67}\n"
          ]
        }
      ]
    }
  ]
}